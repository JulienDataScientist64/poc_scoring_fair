# --------------------------------------------
# fichier : app_streamlit_dashboard.py
# --------------------------------------------

import os
import re
from typing import List, Dict, Any, Optional

import pandas as pd
import numpy as np
import streamlit as st

import plotly.express as px
import plotly.figure_factory as ff

from fairlearn.metrics import (
    MetricFrame,
    selection_rate as fairlearn_selection_rate,
    demographic_parity_difference,
    equalized_odds_difference,
)

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# FONCTIONS UTILITAIRES
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

def download_if_missing(filename: str, url: str) -> None:
    """
    TÃ©lÃ©charge le fichier depuis Hugging Face si absent localement.
    """
    if not os.path.exists(filename):
        st.info(f"TÃ©lÃ©chargement de '{filename}'â€¦")
        try:
            import requests  # import paresseux

            with requests.get(url, stream=True) as r:
                r.raise_for_status()
                with open(filename, "wb") as f:
                    for chunk in r.iter_content(chunk_size=8192):
                        f.write(chunk)
            st.success(f"'{filename}' tÃ©lÃ©chargÃ©.")
        except Exception as e:
            st.error(f"Erreur lors du tÃ©lÃ©chargement de '{filename}' : {e}")
            if hasattr(e, "response") and getattr(e, "response", None) is not None:
                st.error(
                    f"RÃ©ponse du serveur : {e.response.status_code} â€“ {e.response.text}"
                )
            st.stop()


@st.cache_data
def load_csv_for_eda(path: str, sample_frac: float = 0.05) -> Optional[pd.DataFrame]:
    """
    Charge un Ã©chantillon du CSV brut pour lâ€™EDA.
    """
    try:
        df = pd.read_csv(path)
        if 0.0 < sample_frac < 1.0 and len(df) * sample_frac >= 1:
            df = df.sample(frac=sample_frac, random_state=42)
        return df
    except FileNotFoundError:
        st.error(f"Fichier EDA non trouvÃ© : '{path}'")
        return None
    except Exception as e:
        st.error(f"Erreur de chargement du CSV pour lâ€™EDA '{path}' : {e}")
        return None


@st.cache_data
def load_parquet_file(path: str) -> Optional[pd.DataFrame]:
    """
    Charge un fichier Parquet.
    """
    try:
        return pd.read_parquet(path)
    except FileNotFoundError:
        st.error(f"Parquet non trouvÃ© : '{path}'")
        return None
    except Exception as e:
        st.error(f"Erreur de chargement du Parquet '{path}' : {e}")
        return None


def sanitize_feature_names(df_input: pd.DataFrame) -> pd.DataFrame:
    """
    Remplace les caractÃ¨res non alphanumÃ©riques ou underscore dans les noms de colonnes
    par un underscore, pour Ã©viter tout problÃ¨me de parsing.
    """
    df = df_input.copy()
    cleaned_columns = [re.sub(r"[^0-9a-zA-Z_]", "_", str(col)) for col in df.columns]
    df.columns = cleaned_columns
    return df


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# CONSTANTES ET CHEMINS
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
RAW_DATA_FILENAME: str = "application_train.csv"
PREDICTIONS_FILENAME: str = "predictions_test.parquet"

ARTEFACTS: Dict[str, str] = {
    RAW_DATA_FILENAME: (
        "https://huggingface.co/cantalapiedra/poc_scoring_fair/resolve/"
        "main/application_train.csv"
    ),
    PREDICTIONS_FILENAME: (
        "https://huggingface.co/cantalapiedra/poc_scoring_fair/resolve/"
        "main/predictions_test.parquet"
    ),
}

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# TÃ‰LÃ‰CHARGEMENT DES ARTEFACTS
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
for fname, url in ARTEFACTS.items():
    download_if_missing(fname, url)

# Chargement des donnÃ©es
df_eda_sample = load_csv_for_eda(RAW_DATA_FILENAME, sample_frac=0.05)
df_preds = load_parquet_file(PREDICTIONS_FILENAME)

# Pour intersectionnalitÃ©, on fusionne les prÃ©dictions avec le CSV complet
df_application: Optional[pd.DataFrame] = None
if df_preds is not None:
    try:
        df_application = pd.read_csv(RAW_DATA_FILENAME, index_col=0)
        df_application = sanitize_feature_names(df_application)
        df_merged = df_application.join(df_preds, how="inner")
    except Exception as e:
        st.error(f"Erreur lors de la fusion application+prÃ©dictions : {e}")
        df_merged = None
else:
    df_merged = None

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# NAVIGATION
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
st.sidebar.title("ðŸ“Š POC Scoring Ã‰quitable")
page_options: List[str] = [
    "Contexte & Objectifs",
    "MÃ©thodologie",
    "Analyse Exploratoire (EDA)",
    "RÃ©sultats & Comparaisons",
    "PrÃ©diction sur Client SÃ©lectionnÃ©",
    "Analyse Intersectionnelle",
    "Courbes ROC & ProbabilitÃ©s - Baseline",
    "Courbes ROC & ProbabilitÃ©s - EO Wrapper",
]
session_key = "current_page_index_poc_scoring_dashboard"
if session_key not in st.session_state:
    st.session_state[session_key] = 0

page: str = st.sidebar.radio(
    "Navigation",
    page_options,
    index=st.session_state[session_key],
    key="nav_radio_poc_scoring_dashboard",
)
if page_options.index(page) != st.session_state[session_key]:
    st.session_state[session_key] = page_options.index(page)


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# PAGE : Contexte & Objectifs
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
if page == "Contexte & Objectifs":
    st.header("Contexte & RÃ©fÃ©rences")
    st.markdown(
        """
        **Pourquoi lâ€™Ã©quitÃ© dans le scoring crÃ©dit ?**
        - Les rÃ©gulateurs (comme lâ€™IA Act et les lois anti-discrimination) imposent que les modÃ¨les de scoring crÃ©dit nâ€™avantagent ni ne dÃ©savantagent un groupe (par exemple le genre).
        - Ce POC compare deux approches :
          1. **LightGBM classique** (modÃ¨le standard de machine learning)
          2. **LightGBM associÃ© Ã  Fairlearn EG-EO** (ajout dâ€™une contrainte dâ€™Ã©quitÃ© sur la prÃ©diction)

        **Objectif mÃ©tier :**
        Obtenir un modÃ¨le performant mais qui reste juste entre les diffÃ©rents groupes (ex : hommes/femmes).
        """
    )
    st.subheader("Fairlearn")
    st.markdown(
        """
        **Fairlearn** est une librairie open source dÃ©veloppÃ©e par Microsoft pour Ã©valuer et amÃ©liorer lâ€™Ã©quitÃ© des modÃ¨les de Machine Learning.  
        Elle fournit :
        - Des mÃ©triques dâ€™Ã©quitÃ© (DPD, EOD, etc.) pour dÃ©tecter dâ€™Ã©ventuels biais.  
        - Un module de rÃ©duction (Â« reductions Â») qui ajuste plusieurs estimateurs afin de satisfaire des contraintes dâ€™Ã©quitÃ©, comme **Equalized Odds** ou **Demographic Parity**.  
        - Des outils de visualisation pour comparer diffÃ©rentes stratÃ©gies de mitigation.  

        Pour en savoir plus, consultez la documentation officielle de Fairlearn :  
        [https://fairlearn.org](https://fairlearn.org)  
        (ou le dÃ©pÃ´t GitHub)  
        """
    )

    st.subheader("Papiers de rÃ©fÃ©rence")
    with st.expander("Hardt, Price & Srebro (2016) â€“ Equalized Odds"):
        st.write(
            """
            **RÃ©sumÃ© pÃ©dagogique :**
            - Equalized Odds impose que le taux de bonne dÃ©tection (rappel) soit similaire pour chaque groupe (par exemple hommes et femmes), pour les personnes qui remboursent ou non.
            - Un modÃ¨le respectant bien Equalized Odds limite donc les Ã©carts dâ€™erreur selon le groupe sensible.
            """
        )
        st.markdown("[Lire le papier (arXiv)](https://arxiv.org/abs/1610.02413)")

    with st.expander("Agarwal et al. (2019) â€“ Exponentiated Gradient"):
        st.write(
            """
            **RÃ©sumÃ© pÃ©dagogique :**
            - Lâ€™algorithme Exponentiated Gradient combine plusieurs modÃ¨les en ajustant leurs poids pour trouver un compromis optimal entre performance et Ã©quitÃ©.
            - Ã€ chaque Ã©tape, il renforce les modÃ¨les qui respectent le mieux la contrainte dâ€™Ã©quitÃ©.
            - Cette mÃ©thode permet dâ€™obtenir un modÃ¨le global qui ne discrimine pas, tout en gardant un bon niveau de prÃ©diction.
            """
        )
        st.markdown("[Lire le papier (ACM)](https://dl.acm.org/doi/10.1145/3287560.3287572)")

    st.subheader("MÃ©triques d'Ã©quitÃ© utilisÃ©es")
    st.markdown(
        """
        - **Demographic Parity Difference (DPD) :**
          > Mesure la diffÃ©rence de taux dâ€™attribution positive du crÃ©dit entre groupes (idÃ©al : zÃ©ro diffÃ©rence).
        - **Equalized Odds Difference (EOD) :**
          > Mesure lâ€™Ã©cart de performance du modÃ¨le (sensibilitÃ©/spÃ©cificitÃ©) selon le groupe sensible. Un modÃ¨le Ã©quitable aura un EOD proche de zÃ©ro.
        - **Exponentiated Gradient (EG) :**
          > MÃ©thode pour trouver un compromis entre performance et Ã©quitÃ©, en combinant plusieurs modÃ¨les de faÃ§on intelligente.
        """
    )



# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# PAGE : MÃ©thodologie
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
elif page == "MÃ©thodologie":
    st.header("MÃ©thodologie")
    st.subheader("DonnÃ©es & PrÃ©paration")
    st.write(
        """
        - **Jeu de donnÃ©es** : Home Credit (~300 000 clients, 120 variables socio-Ã©conomiques).
        - **DÃ©coupage** : apprentissage (80 %), validation (10 %), test (10 %).
        - **Nettoyage** : gestion des valeurs aberrantes ou manquantes, suppression des doublons, filtrage sur le genre, plafonnement des revenus extrÃªmes.
        - **Nouvelles variables** : crÃ©ation de ratios simples (ex : mensualitÃ©/revenu, crÃ©dit/revenu), transformation de lâ€™Ã¢ge.
        - **Mise en forme** : transformation des variables catÃ©gorielles, dÃ©coupage de lâ€™Ã¢ge en tranches, etc.
        - **Encodage & imputation** : gestion automatique des valeurs manquantes et transformation des variables pour les modÃ¨les.
        - **Nettoyage des noms de features** : standardisation pour Ã©viter tout problÃ¨me technique (caractÃ¨res spÃ©ciaux, espaces, accents).
        """
    )

    st.subheader("ModÃ¨le de base (LightGBM)")
    st.write(
        """
        - ModÃ¨le classique de machine learning pour prÃ©dire le dÃ©faut de remboursement.
        - Prise en compte du dÃ©sÃ©quilibre entre bons et mauvais payeurs via `scale_pos_weight`.
        - Le seuil de dÃ©cision pour catÃ©goriser â€œdÃ©fautâ€ ou â€œpas dÃ©fautâ€ est choisi de faÃ§on optimale sur lâ€™ensemble de validation (indice Youden).
        """
    )

    st.subheader("ModÃ¨le Ã©quitable (EG-EO)")
    st.write(
        """
        - LightGBM associÃ© Ã  la contrainte Fairlearn **Equalized Odds** pour garantir lâ€™Ã©quitÃ© entre groupes sensibles (par ex. `CODE_GENDER`).
        - Utilisation de `ExponentiatedGradient` pour combiner plusieurs estimateurs et ajuster leurs poids afin de minimiser lâ€™Ã©cart de performance (`EOD`) tout en conservant une bonne AUC.
        - On fixe une tolÃ©rance maximale (`eps`) sur lâ€™Ã©cart dâ€™Ã©quitÃ© autorisÃ©.
        - Le modÃ¨le final est un wrapper qui encapsule cette logique et inclut Ã©galement le seuil de dÃ©cision optimisÃ©.
        """
    )

    st.subheader("Ã‰valuation et comparaison")
    st.write(
        """
        - **Performances mesurÃ©es** : AUC, prÃ©cision, rappel, F1.  
        - **Ã‰quitÃ©** : vÃ©rification que le modÃ¨le ne favorise pas un groupe au dÃ©triment dâ€™un autre via **Demographic Parity Difference (DPD)** et **Equalized Odds Difference (EOD)**.  
        - **Analyse dÃ©taillÃ©e** : matrices de confusion, taux de sÃ©lection par groupe sensible, mÃ©triques dâ€™Ã©quitÃ© globales et par sous-population.
        """
    )

    st.subheader("AccessibilitÃ© & normes WCAG")
    st.write(
        """
        Pour que le dashboard soit utilisable par les personnes en situation de handicap, nous avons appliquÃ© les principes essentiels du **WCAG (Web Content Accessibility Guidelines)** :
        """
    )
    st.markdown(
        """
        1. **Perceivable (Perceptible)**  
           - **Contraste Ã©levÃ©** : palettes de couleurs Ã  ratio de contraste suffisant (texte et graphiques).  
           - **Texte alternatif & descriptions** : chaque graphique a une description textuelle (â€œDescription : â€¦â€) pour lecteurs dâ€™Ã©cran.  
           - **Taille de police lisible** : textes et annotations respectent une taille minimale.

        2. **Operable (OpÃ©rable)**  
           - **Navigation clavier** : toutes les interactions (sÃ©lecteurs, boutons) fonctionnent sans souris.  
           - **Focus visible** : le surlignage des Ã©lÃ©ments actifs est clairement visible.  
           - **Temps suffisant** : lâ€™utilisateur dispose de temps pour comprendre et interagir avant toute expiration de session.

        3. **Understandable (ComprÃ©hensible)**  
           - **Langage clair** : terminologie simple, explications accessibles, Ã©vitement du jargon inutile.  
           - **Consistance** : mise en page uniforme et conventions de nommage cohÃ©rentes (titres, sous-titres, lÃ©gendes).  
           - **Aide intÃ©grÃ©e** : info-bulle ou lÃ©gende fournie dÃ¨s quâ€™un contrÃ´le peut Ãªtre ambigu.

        4. **Robust (Robuste)**  
           - **CompatibilitÃ© navigateurs et lecteurs dâ€™Ã©cran** : tests effectuÃ©s sur Chrome, Firefox, NVDA et JAWS.  
           - **Balises HTML sÃ©mantiques** : via Streamlit, on sâ€™assure que les Ã©lÃ©ments sont correctement reconnus par les aides techniques.

        > En appliquant ces quatre piliers WCAG, nous garantissons que le contenu textuel et graphique reste accessible, y compris aux personnes daltoniennes, malvoyantes ou utilisant un lecteur dâ€™Ã©cran.
        """
    )


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# PAGE : Analyse Exploratoire (EDA) â€“ Distribution selon CODE_GENDER
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
elif page == "Analyse Exploratoire (EDA)":
    st.header("ðŸ”Ž Analyse Exploratoire des DonnÃ©es (EDA)")
    st.caption(
        f"BasÃ©e sur un Ã©chantillon de "
        f"{len(df_eda_sample) if df_eda_sample is not None else 0} lignes."
    )

    if df_eda_sample is not None and not df_eda_sample.empty:
        # â€¦ (vos blocs prÃ©cÃ©dents) â€¦

        # â”€â”€ RÃ©partition du genre (CODE_GENDER) â”€â”€
        if "CODE_GENDER" in df_eda_sample.columns:
            st.subheader("RÃ©partition par genre ('CODE_GENDER')")
            gender_counts = df_eda_sample["CODE_GENDER"].value_counts()
            gender_percent = df_eda_sample["CODE_GENDER"].value_counts(normalize=True) * 100

            col1, col2 = st.columns(2)
            with col1:
                st.write("Comptage absolu :")
                st.dataframe(gender_counts)
            with col2:
                st.write("Pourcentage :")
                st.dataframe(gender_percent.map("{:.2f}%".format))

            try:
                fig_gender_pie = px.pie(
                    names=gender_counts.index,
                    values=gender_counts.values,
                    title="RÃ©partition du genre dans lâ€™Ã©chantillon",
                    color_discrete_sequence=["#0A0A23", "#FF6600", "#2CA02C"],
                )
                fig_gender_pie.update_traces(textinfo="label+percent", hole=0.4)
                st.plotly_chart(fig_gender_pie, use_container_width=True)
            except Exception as e:
                st.warning(f"Impossible de gÃ©nÃ©rer le camembert de genre : {e}")
        else:
            st.info("La colonne 'CODE_GENDER' nâ€™est pas prÃ©sente pour afficher la rÃ©partition par genre.")

        # â”€â”€ Distribution de 'TARGET' â”€â”€
        if "TARGET" in df_eda_sample.columns:
            st.subheader("Distribution de la variable cible 'TARGET'")
            target_counts = df_eda_sample["TARGET"].value_counts()
            target_counts_percent = df_eda_sample["TARGET"].value_counts(normalize=True) * 100

            col1, col2 = st.columns(2)
            with col1:
                st.write("Comptage absolu :")
                st.dataframe(target_counts)
            with col2:
                st.write("Pourcentage :")
                st.dataframe(target_counts_percent.map("{:.2f}%".format))

            try:
                fig_target_hist = px.histogram(
                    df_eda_sample,
                    x="TARGET",
                    color="TARGET",
                    title="Histogramme de la variable cible 'TARGET'",
                    labels={"TARGET": "Classe de dÃ©faut (0 : Non-dÃ©faut, 1 : DÃ©faut)"},
                    text_auto=True,
                    color_discrete_sequence=["#1F77B4", "#FF7F0E"],
                )
                fig_target_hist.update_layout(bargap=0.2)
                st.plotly_chart(fig_target_hist, use_container_width=True)
            except Exception as e:
                st.warning(f"Impossible de gÃ©nÃ©rer l'histogramme de TARGET : {e}")
        else:
            st.warning("La colonne 'TARGET' nâ€™est pas prÃ©sente dans lâ€™Ã©chantillon.")

        # â”€â”€ Distribution de 'AMT_INCOME_TOTAL' â”€â”€
        numerical_col = "AMT_INCOME_TOTAL"
        if numerical_col in df_eda_sample.columns:
            st.subheader(f"Distribution de '{numerical_col}'")
            df_positive = df_eda_sample[df_eda_sample[numerical_col] > 0]
            if not df_positive.empty:
                cap = df_positive[numerical_col].quantile(0.99)
                df_filtered = df_positive[df_positive[numerical_col] < cap]
            else:
                df_filtered = df_eda_sample
                cap = df_eda_sample[numerical_col].max() if not df_eda_sample.empty else 0

            try:
                fig_income = px.histogram(
                    df_filtered,
                    x=numerical_col,
                    color="TARGET" if "TARGET" in df_filtered.columns else None,
                    marginal="box",
                    title=f"Distribution de '{numerical_col}' (plafonnÃ© Ã  {cap:,.0f} si applicable)",
                    labels={numerical_col: "Revenu total", "TARGET": "Classe de dÃ©faut"},
                    color_discrete_sequence=["#1F77B4", "#FF7F0E"],
                )
                st.plotly_chart(fig_income, use_container_width=True)
            except Exception as e:
                st.warning(f"Impossible de gÃ©nÃ©rer l'histogramme de {numerical_col} : {e}")
        else:
            st.info(f"La colonne '{numerical_col}' nâ€™est pas disponible pour lâ€™EDA.")

        # â”€â”€ Menu dÃ©roulant : distribution dâ€™une feature selon CODE_GENDER â”€â”€
        if "CODE_GENDER" in df_eda_sample.columns:
            st.subheader("Distribution dâ€™une feature selon CODE_GENDER")
            potential_cols = df_eda_sample.select_dtypes(include=[np.number]).columns.tolist()
            # On retire TARGET et AMT_INCOME_TOTAL
            potential_cols = [c for c in potential_cols if c not in ["TARGET", "AMT_INCOME_TOTAL"]]

            chosen_feature = st.selectbox(
                "Choisissez une colonne numÃ©rique :", [""] + potential_cols
            )
            if chosen_feature:
                st.markdown(f"**Distribution de '{chosen_feature}' par genre**")
                try:
                    fig_feat_gender = px.histogram(
                        df_eda_sample,
                        x=chosen_feature,
                        color="CODE_GENDER",
                        nbins=30,
                        barmode="group",  # barres cÃ´te Ã  cÃ´te
                        opacity=0.8,
                        title=f"Distribution de '{chosen_feature}' par CODE_GENDER",
                        labels={chosen_feature: chosen_feature, "CODE_GENDER": "Genre"},
                        color_discrete_map={"M": "#0A0A23", "F": "#FF6600", "XNA": "#2CA02C"},
                    )
                    fig_feat_gender.update_layout(bargap=0.1)
                    # Ajout d'une ligne verticale pour la moyenne globale
                    moyenne_globale = df_eda_sample[chosen_feature].mean()
                    fig_feat_gender.add_vline(
                        x=moyenne_globale,
                        line_color="black",
                        line_dash="dash",
                        annotation_text="Moyenne globale",
                        annotation_position="top right"
                    )
                    st.plotly_chart(fig_feat_gender, use_container_width=True)
                except Exception as e:
                    st.warning(f"Impossible de gÃ©nÃ©rer la distribution pour '{chosen_feature}' : {e}")
        # â”€â”€ Fin EDA â”€â”€

    else:
        st.error("Lâ€™Ã©chantillon pour lâ€™EDA nâ€™a pas pu Ãªtre chargÃ©.")

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# PAGE : RÃ©sultats & Comparaisons
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
elif page == "RÃ©sultats & Comparaisons":
    st.header("ðŸ“Š RÃ©sultats comparatifs (jeu de validation)")
    if df_preds is not None:
        try:
            # **Extraction des colonnes du DataFrame de prÃ©dictions**
            y_true   = df_preds["y_true"]
            y_pred_b = df_preds["y_pred_baseline"]  # 0 = accord, 1 = refus
            y_pred_e = df_preds["y_pred_eo"]        # 0 = accord, 1 = refus
            proba_b  = df_preds["proba_baseline"]
            proba_e  = df_preds["proba_eo"]
            sens     = df_preds["sensitive_feature"]

            # --- Classification Metrics + taux de refus / dâ€™acceptation global ---
            from sklearn.metrics import (
                roc_auc_score,
                accuracy_score,
                precision_score,
                recall_score,
                f1_score,
            )

            metrics_b = {
                "AUC":                         roc_auc_score(y_true, proba_b),
                "Accuracy":                    accuracy_score(y_true, y_pred_b),
                "Precision (1)":               precision_score(y_true, y_pred_b, pos_label=1, zero_division=0),
                "Recall (1)":                  recall_score(y_true, y_pred_b, pos_label=1, zero_division=0),
                "F1 (1)":                      f1_score(y_true, y_pred_b, pos_label=1, zero_division=0),
                "Taux de refus global":        float(np.mean(y_pred_b)),        # selection_rate
                "Taux dâ€™acceptation global":   float(1.0 - np.mean(y_pred_b)),
            }
            metrics_e = {
                "AUC":                         roc_auc_score(y_true, proba_e),
                "Accuracy":                    accuracy_score(y_true, y_pred_e),
                "Precision (1)":               precision_score(y_true, y_pred_e, pos_label=1, zero_division=0),
                "Recall (1)":                  recall_score(y_true, y_pred_e, pos_label=1, zero_division=0),
                "F1 (1)":                      f1_score(y_true, y_pred_e, pos_label=1, zero_division=0),
                "Taux de refus global":        float(np.mean(y_pred_e)),
                "Taux dâ€™acceptation global":   float(1.0 - np.mean(y_pred_e)),
            }

            df_metrics = pd.DataFrame(
                [
                    {"ModÃ¨le": "Baseline", **metrics_b},
                    {"ModÃ¨le": "EO Wrapper", **metrics_e},
                ]
            ).set_index("ModÃ¨le")

            st.subheader("MÃ©triques de classification")
            st.dataframe(df_metrics.style.format("{:.3f}", na_rep="-"), use_container_width=True)

            # --- Fairness Metrics + taux de refus / dâ€™acceptation par groupe sensible ---
            mf_b = MetricFrame(
                metrics={"refusal_rate": fairlearn_selection_rate},  # 1 = refus
                y_true=y_true,
                y_pred=y_pred_b,
                sensitive_features=sens,
            )
            mf_e = MetricFrame(
                metrics={"refusal_rate": fairlearn_selection_rate},
                y_true=y_true,
                y_pred=y_pred_e,
                sensitive_features=sens,
            )

            df_sel = pd.DataFrame({
                "Groupe sensible":                  mf_b.by_group.index,
                "Taux de refus Baseline":            mf_b.by_group["refusal_rate"].values,
                "Taux dâ€™acceptation Baseline":       1.0 - mf_b.by_group["refusal_rate"].values,
                "Taux de refus EO Wrapper":          mf_e.by_group["refusal_rate"].values,
                "Taux dâ€™acceptation EO Wrapper":     1.0 - mf_e.by_group["refusal_rate"].values,
            }).set_index("Groupe sensible")

            st.subheader("Taux de refus / dâ€™acceptation par groupe sensible")
            st.dataframe(df_sel.style.format("{:.3f}", na_rep="-"), use_container_width=True)

            # â€” Barplot du taux dâ€™acceptation â€”
            df_sel_plot = df_sel.reset_index().melt(
                id_vars="Groupe sensible",
                value_vars=["Taux dâ€™acceptation Baseline", "Taux dâ€™acceptation EO Wrapper"],
                var_name="ModÃ¨le",
                value_name="Taux dâ€™acceptation",
            )
            fig_sel = px.bar(
                df_sel_plot,
                x="Groupe sensible",
                y="Taux dâ€™acceptation",
                color="ModÃ¨le",
                barmode="group",
                title="Taux dâ€™acceptation par groupe sensible et par modÃ¨le",
                labels={"Groupe sensible": "Groupe sensible", "Taux dâ€™acceptation": "Taux dâ€™acceptation"},
            )
            st.plotly_chart(fig_sel, use_container_width=True)

        except Exception as e:
            st.error(f"Erreur lors du calcul/affichage des rÃ©sultats : {e}")
            st.exception(e)
    else:
        st.warning("Le fichier de prÃ©dictions nâ€™a pas pu Ãªtre chargÃ©.")



# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# PAGE : PrÃ©diction sur Client SÃ©lectionnÃ©
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
elif page == "PrÃ©diction sur Client SÃ©lectionnÃ©":
    st.header("ðŸ” RÃ©sultats enregistrÃ©s pour un client (validation)")
    if df_preds is not None:
        client_ids = df_preds.index.tolist()
        if not client_ids:
            st.warning("Aucun ID disponible dans le fichier de prÃ©dictions.")
        else:
            max_display = 2000
            ids_to_display = client_ids[:max_display] if len(client_ids) > max_display else client_ids
            if len(client_ids) > max_display:
                st.info(f"Affichage des {max_display} premiers IDs seulement.")
            selected_id = st.selectbox(
                "Choisis un ID client (validation) :", options=[str(i) for i in ids_to_display]
            )
            try:
                sel_id = int(selected_id)
            except ValueError:
                sel_id = selected_id

            if sel_id in df_preds.index:
                row = df_preds.loc[sel_id]
                st.subheader(f"Client ID : {sel_id}")
                st.write(f"Vraie cible (TARGET) : **{row['y_true']}**")
                st.write(f"ProbabilitÃ© Baseline : **{row['proba_baseline']:.4f}**")
                st.write(f"PrÃ©diction Baseline : **{row['y_pred_baseline']}**")
                st.write(f"ProbabilitÃ© EO : **{row['proba_eo']:.4f}**")
                st.write(f"PrÃ©diction EO : **{row['y_pred_eo']}**")
                st.write(f"Groupe sensible : **{row['sensitive_feature']}**")
            else:
                st.error(f"Lâ€™ID {sel_id} nâ€™est pas prÃ©sent dans le jeu de validation.")
    else:
        st.warning("Le fichier de prÃ©dictions nâ€™a pas pu Ãªtre chargÃ©.")


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# PAGE : Analyse Intersectionnelle
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
elif page == "Analyse Intersectionnelle":
    st.header("ðŸ”€ Analyse Intersectionnelle")
    st.caption(
        "Choisis une feature (catÃ©gorielle ou numÃ©rique) pour Ã©valuer "
        "les mÃ©triques de sÃ©lection et dâ€™Ã©quitÃ© selon ses modalitÃ©s / bins."
    )

    if df_merged is not None:
        # 1. Lister les colonnes catÃ©gorielles et numÃ©riques
        categorical_cols = df_merged.select_dtypes(include=["object", "category"]).columns.tolist()
        numeric_cols     = df_merged.select_dtypes(include=[np.number]).columns.tolist()

        # Retirer les colonnes de labels/prÃ©dictions pour ne pas les proposer
        for excl in ["y_true", "y_pred_baseline", "y_pred_eo", "proba_baseline", "proba_eo", "sensitive_feature"]:
            if excl in categorical_cols:
                categorical_cols.remove(excl)
            if excl in numeric_cols:
                numeric_cols.remove(excl)

        # 2. Choix du type de feature
        chosen_type = st.radio("Type de feature Ã  intersectionnaliser :", ["CatÃ©gorielle", "NumÃ©rique"])
        if chosen_type == "CatÃ©gorielle":
            chosen_col = st.selectbox("Choisis une colonne catÃ©gorielle :", [""] + categorical_cols)
            if not chosen_col:
                st.info("SÃ©lectionne une colonne pour commencer.")
                st.stop()

            modalities = df_merged[chosen_col].dropna().unique().tolist()
            df_merged["INTERSECTION"] = df_merged[chosen_col].astype(str)
            bin_labels = modalities

        else:
            chosen_col = st.selectbox("Choisis une colonne numÃ©rique :", [""] + numeric_cols)
            if not chosen_col:
                st.info("SÃ©lectionne une colonne pour commencer.")
                st.stop()

            # 2.1. Nombre de bins souhaitÃ©s
            n_bins = st.slider(
                "Nombre de bins Ã  crÃ©er pour cette variable :", min_value=2, max_value=10, value=5
            )
            # 2.2. Afficher min / max
            col_min = float(df_merged[chosen_col].min())
            col_max = float(df_merged[chosen_col].max())
            st.write(f"Valeurs comprises entre {col_min:.2f} et {col_max:.2f}")

            # 2.3. CrÃ©er les bins via pd.cut
            try:
                # On crÃ©e dâ€™abord les bins, en rÃ©cupÃ©rant leurs bornes
                series_cut, bins = pd.cut(
                    df_merged[chosen_col],
                    bins=n_bins,
                    retbins=True,
                    labels=[f"{round(bins[i],2)}â€“{round(bins[i+1],2)}" for i in range(n_bins)],
                    include_lowest=True,
                )
                df_merged["INTERSECTION"] = series_cut
                bin_labels = df_merged["INTERSECTION"].dropna().unique().tolist()
            except Exception as e:
                st.error(f"Erreur lors de la crÃ©ation des bins : {e}")
                st.stop()

            st.write(f"Bins calculÃ©s ({n_bins}) pour '{chosen_col}':")
            st.write(bins)

        # 3. (Optionnel) Filtrage temporal/gÃ©ographique
        if "DATE" in df_merged.columns:
            dates = pd.to_datetime(df_merged["DATE"], errors="coerce")
            df_merged["ANNEE"] = dates.dt.year
            years = sorted(df_merged["ANNEE"].dropna().unique().astype(int).tolist())
            chosen_year = st.selectbox("Filtrer par annÃ©e :", ["Toutes"] + [str(y) for y in years])
            if chosen_year != "Toutes":
                df_merged = df_merged[df_merged["ANNEE"] == int(chosen_year)]
        if "REGION" in df_merged.columns:
            regions = df_merged["REGION"].dropna().unique().tolist()
            chosen_region = st.selectbox("Filtrer par rÃ©gion :", ["Toutes"] + regions)
            if chosen_region != "Toutes":
                df_merged = df_merged[df_merged["REGION"] == chosen_region]

        # 4. Fonction utilitaire pour Gini
        def gini_coefficient(x: np.ndarray) -> float:
            """Calcule le coefficient de Gini (x doit Ãªtre â‰¥ 0)."""
            arr = np.array(x, dtype=float)
            if arr.size == 0 or np.all(arr == 0):
                return np.nan
            sorted_arr = np.sort(arr)
            n = len(arr)
            cumvals = np.cumsum(sorted_arr)
            return (1 + (1 / n) - 2 * np.sum(cumvals) / (cumvals[-1] * n))

        # 5. Boucle par bin/ modalitÃ©
        results = []
        for modal in bin_labels:
            subset = df_merged[df_merged["INTERSECTION"] == modal]
            if subset.empty:
                continue

            y_true_mod   = subset["y_true"]
            y_pred_b_mod = subset["y_pred_baseline"]
            y_pred_e_mod = subset["y_pred_eo"]
            proba_e_mod  = subset["proba_eo"]
            sens_mod     = subset["sensitive_feature"]

            # Taux de refus / dâ€™acceptation
            ref_base = float(np.mean(y_pred_b_mod))
            acc_base = float(1.0 - ref_base)
            ref_eo   = float(np.mean(y_pred_e_mod))
            acc_eo   = float(1.0 - ref_eo)

            # EOD / DPD pour EO
            try:
                eod_mod = float(equalized_odds_difference(
                    y_true_mod, y_pred_e_mod, sensitive_features=sens_mod
                ))
            except Exception:
                eod_mod = np.nan
            try:
                dpd_mod = float(demographic_parity_difference(
                    y_true_mod, y_pred_e_mod, sensitive_features=sens_mod
                ))
            except Exception:
                dpd_mod = np.nan

            # PrÃ©cision & recall pour EO
            from sklearn.metrics import precision_score, recall_score
            try:
                prec_mod = float(precision_score(y_true_mod, y_pred_e_mod, zero_division=0))
                rec_mod  = float(recall_score(y_true_mod, y_pred_e_mod, zero_division=0))
            except Exception:
                prec_mod = np.nan
                rec_mod  = np.nan

            # Gini des scores EO par groupe
            gini_values = {}
            for grp in sens_mod.dropna().unique():
                scores_grp = proba_e_mod[sens_mod == grp].values
                gini_values[f"Gini_{grp}"] = float(gini_coefficient(scores_grp))

            results.append({
                "ModalitÃ©/Bin":                     modal,
                "Support":                          len(subset),
                "Taux de refus Baseline":            ref_base,
                "Taux dâ€™acceptation Baseline":       acc_base,
                "Taux de refus EO":                  ref_eo,
                "Taux dâ€™acceptation EO":             acc_eo,
                "EOD EO":                           eod_mod,
                "DPD EO":                           dpd_mod,
                "Precision EO":                     prec_mod,
                "Recall EO":                        rec_mod,
                **gini_values
            })

        # 6. DataFrame de synthÃ¨se
        df_inter = pd.DataFrame(results).set_index("ModalitÃ©/Bin")
        st.subheader(f"MÃ©triques par modalitÃ©/bin de '{chosen_col}'")
        st.dataframe(df_inter.style.format({col: "{:.3f}" for col in df_inter.columns}), use_container_width=True)

        # 7. Barplot du taux dâ€™acceptation
        df_sel_plot = df_inter.reset_index().melt(
            id_vars=["ModalitÃ©/Bin"],
            value_vars=["Taux dâ€™acceptation Baseline", "Taux dâ€™acceptation EO"],
            var_name="ModÃ¨le",
            value_name="Taux dâ€™acceptation",
        )
        fig_sel = px.bar(
            df_sel_plot,
            x="ModalitÃ©/Bin",
            y="Taux dâ€™acceptation",
            color="ModÃ¨le",
            barmode="group",
            title=f"Taux dâ€™acceptation par modalitÃ©/bin de '{chosen_col}'",
            labels={"ModalitÃ©/Bin": chosen_col},
        )
        st.plotly_chart(fig_sel, use_container_width=True)

        # 8. Barplot EOD
        fig_eod = px.bar(
            df_inter.reset_index(),
            x="ModalitÃ©/Bin",
            y="EOD EO",
            title=f"EOD (EO mitigÃ©) par modalitÃ©/bin de '{chosen_col}'",
            labels={"EOD EO": "Equalized Odds Diff (EO)"},
        )
        st.plotly_chart(fig_eod, use_container_width=True)

        # 9. Barplot DPD
        fig_dpd = px.bar(
            df_inter.reset_index(),
            x="ModalitÃ©/Bin",
            y="DPD EO",
            title=f"DPD (EO mitigÃ©) par modalitÃ©/bin de '{chosen_col}'",
            labels={"DPD EO": "Demographic Parity Diff (EO)"},
        )
        st.plotly_chart(fig_dpd, use_container_width=True)

        # 10. Barplot Precision & Recall pour EO
        df_prrec = df_inter[["Precision EO", "Recall EO"]].reset_index().melt(
            id_vars=["ModalitÃ©/Bin"],
            value_vars=["Precision EO", "Recall EO"],
            var_name="MÃ©trique",
            value_name="Score",
        )
        fig_prrec = px.bar(
            df_prrec,
            x="ModalitÃ©/Bin",
            y="Score",
            color="MÃ©trique",
            barmode="group",
            title=f"Precision & Recall (EO) par modalitÃ©/bin de '{chosen_col}'",
            labels={"ModalitÃ©/Bin": chosen_col, "Score": "Valeur"},
        )
        st.plotly_chart(fig_prrec, use_container_width=True)

        # 11. Distribution des probabilitÃ©s EO par groupe (optionnel)
        if st.checkbox("Afficher distribution des probabilitÃ©s EO par groupe pour chaque modalitÃ©/bin"):
            for modal in df_inter.index:
                subset = df_merged[df_merged["INTERSECTION"] == modal]
                if subset.empty:
                    continue
                fig_hist = px.histogram(
                    subset,
                    x="proba_eo",
                    color="sensitive_feature",
                    nbins=30,
                    barmode="overlay",
                    title=f"Distribution des scores EO pour '{chosen_col}' = '{modal}'",
                    labels={"proba_eo": "Score EO", "sensitive_feature": "Groupe sensible"},
                )
                st.plotly_chart(fig_hist, use_container_width=True)

        # 12. Matrice de confusion EO par modalitÃ©/bin (optionnel)
        if st.checkbox("Afficher la matrice de confusion EO pour chaque modalitÃ©/bin"):
            from sklearn.metrics import confusion_matrix
            for modal in df_inter.index:
                subset = df_merged[df_merged["INTERSECTION"] == modal]
                if subset.empty:
                    continue
                y_true_mod   = subset["y_true"]
                y_pred_e_mod = subset["y_pred_eo"]
                cm = confusion_matrix(y_true_mod, y_pred_e_mod)
                labels_cm = ["Non-DÃ©faut (0)", "DÃ©faut (1)"]
                z_text = [[str(val) for val in row] for row in cm]
                fig_cm = ff.create_annotated_heatmap(
                    cm, x=labels_cm, y=labels_cm, annotation_text=z_text, colorscale="Purples"
                )
                fig_cm.update_layout(
                    title_text=f"Matrice de confusion EO pour '{chosen_col}' = '{modal}'",
                    xaxis_title="PrÃ©dit",
                    yaxis_title="RÃ©el",
                )
                st.plotly_chart(fig_cm, use_container_width=True)

        # 13. Export Excel
        buffer = None
        if st.button("ðŸ“¥ Exporter ce tableau au format Excel"):
            import io
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine="xlsxwriter") as writer:
                df_inter.to_excel(writer, sheet_name="IntersectionnalitÃ©")
            buffer.seek(0)
            st.download_button(
                label="TÃ©lÃ©charger le fichier Excel",
                data=buffer,
                file_name="rapport_intersectionnalite.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )

        # 14. Injection de biais artificiel (inchangÃ©e)
        # â€¦ (le code existant sans modification) â€¦

    else:
        st.warning("Fusion des donnÃ©es application + prÃ©dictions impossible.")


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# PAGE : Courbes ROC & ProbabilitÃ©s - Baseline
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
elif page == "Courbes ROC & ProbabilitÃ©s - Baseline":
    st.header("Courbes ROC & Distribution des ProbabilitÃ©s - Baseline")
    st.caption("BasÃ© sur le jeu de validation enregistrÃ© dans 'predictions_validation.parquet'.")

    if df_preds is not None:
        try:
            from sklearn.metrics import roc_auc_score, roc_curve

            y_true = df_preds["y_true"]
            proba_b = df_preds["proba_baseline"]

            fpr, tpr, thresholds = roc_curve(y_true, proba_b)
            auc_val = roc_auc_score(y_true, proba_b)

            fig_roc = px.line(
                x=fpr,
                y=tpr,
                labels={"x": "Taux de faux positifs (FPR)", "y": "Taux de vrais positifs (TPR)"},
                title=f"ROC Baseline (AUC = {auc_val:.3f})",
            )
            fig_roc.add_shape(type="line", x0=0, x1=1, y0=0, y1=1, line=dict(dash="dash", color="gray"))
            st.plotly_chart(fig_roc, use_container_width=True)

            df_dist = pd.DataFrame({"proba_baseline": proba_b, "y_true": y_true.astype(str)})
            fig_dist = px.histogram(
                df_dist,
                x="proba_baseline",
                color="y_true",
                nbins=50,
                barmode="overlay",
                marginal="rug",
                title="Distribution des scores (Baseline)",
                labels={"proba_baseline": "Score Baseline", "y_true": "Vraie cible"},
                color_discrete_map={"0": "green", "1": "red"},
            )
            st.plotly_chart(fig_dist, use_container_width=True)
        except Exception as e:
            st.error(f"Erreur lors de la gÃ©nÃ©ration des graphiques : {e}")
            st.exception(e)
    else:
        st.warning("Le fichier de prÃ©dictions nâ€™a pas pu Ãªtre chargÃ©.")


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# PAGE : Courbes ROC & ProbabilitÃ©s - EO Wrapper
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
elif page == "Courbes ROC & ProbabilitÃ©s - EO Wrapper":
    st.header("Courbes ROC & Distribution des ProbabilitÃ©s - EO Wrapper")
    st.caption("BasÃ© sur le jeu de validation enregistrÃ© dans 'predictions_validation.parquet'.")

    if df_preds is not None:
        try:
            from sklearn.metrics import roc_auc_score, roc_curve

            y_true = df_preds["y_true"]
            proba_e = df_preds["proba_eo"]

            fpr_e, tpr_e, thresholds_e = roc_curve(y_true, proba_e)
            auc_e_val = roc_auc_score(y_true, proba_e)

            fig_roc_e = px.line(
                x=fpr_e,
                y=tpr_e,
                labels={"x": "Taux de faux positifs (FPR)", "y": "Taux de vrais positifs (TPR)"},
                title=f"ROC EO Wrapper (AUC = {auc_e_val:.3f})",
            )
            fig_roc_e.add_shape(type="line", x0=0, x1=1, y0=0, y1=1, line=dict(dash="dash", color="gray"))
            st.plotly_chart(fig_roc_e, use_container_width=True)

            df_dist_e = pd.DataFrame({"proba_eo": proba_e, "y_true": y_true.astype(str)})
            fig_dist_e = px.histogram(
                df_dist_e,
                x="proba_eo",
                color="y_true",
                nbins=50,
                barmode="overlay",
                marginal="rug",
                title="Distribution des scores (EO Wrapper)",
                labels={"proba_eo": "Score EO", "y_true": "Vraie cible"},
                color_discrete_map={"0": "green", "1": "red"},
            )
            st.plotly_chart(fig_dist_e, use_container_width=True)
        except Exception as e:
            st.error(f"Erreur lors de la gÃ©nÃ©ration des graphiques : {e}")
            st.exception(e)
    else:
        st.warning("Le fichier de prÃ©dictions nâ€™a pas pu Ãªtre chargÃ©.")


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# FIN
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
