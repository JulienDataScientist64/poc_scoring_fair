# --------------------------------------------
# fichier : app_streamlit_dashboard.py
# --------------------------------------------

import os
import re
from typing import List, Dict, Any, Optional

import pandas as pd
import numpy as np
import streamlit as st

import plotly.express as px
import plotly.figure_factory as ff

from fairlearn.metrics import (
    MetricFrame,
    selection_rate as fairlearn_selection_rate,
    demographic_parity_difference,
    equalized_odds_difference,
)

# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
# FONCTIONS UTILITAIRES
# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî

def download_if_missing(filename: str, url: str) -> None:
    """
    T√©l√©charge le fichier depuis Hugging Face si absent localement.
    """
    if not os.path.exists(filename):
        st.info(f"T√©l√©chargement de '{filename}'‚Ä¶")
        try:
            import requests  # import paresseux

            with requests.get(url, stream=True) as r:
                r.raise_for_status()
                with open(filename, "wb") as f:
                    for chunk in r.iter_content(chunk_size=8192):
                        f.write(chunk)
            st.success(f"'{filename}' t√©l√©charg√©.")
        except Exception as e:
            st.error(f"Erreur lors du t√©l√©chargement de '{filename}' : {e}")
            if hasattr(e, "response") and getattr(e, "response", None) is not None:
                st.error(
                    f"R√©ponse du serveur : {e.response.status_code} ‚Äì {e.response.text}"
                )
            st.stop()


@st.cache_data
def load_csv_for_eda(path: str, sample_frac: float = 0.05) -> Optional[pd.DataFrame]:
    """
    Charge un √©chantillon du CSV brut pour l‚ÄôEDA.
    """
    try:
        df = pd.read_csv(path)
        if 0.0 < sample_frac < 1.0 and len(df) * sample_frac >= 1:
            df = df.sample(frac=sample_frac, random_state=42)
        return df
    except FileNotFoundError:
        st.error(f"Fichier EDA non trouv√© : '{path}'")
        return None
    except Exception as e:
        st.error(f"Erreur de chargement du CSV pour l‚ÄôEDA '{path}' : {e}")
        return None


@st.cache_data
def load_parquet_file(path: str) -> Optional[pd.DataFrame]:
    """
    Charge un fichier Parquet.
    """
    try:
        return pd.read_parquet(path)
    except FileNotFoundError:
        st.error(f"Parquet non trouv√© : '{path}'")
        return None
    except Exception as e:
        st.error(f"Erreur de chargement du Parquet '{path}' : {e}")
        return None


def sanitize_feature_names(df_input: pd.DataFrame) -> pd.DataFrame:
    """
    Remplace les caract√®res non alphanum√©riques ou underscore dans les noms de colonnes
    par un underscore, pour √©viter tout probl√®me de parsing.
    """
    df = df_input.copy()
    cleaned_columns = [re.sub(r"[^0-9a-zA-Z_]", "_", str(col)) for col in df.columns]
    df.columns = cleaned_columns
    return df


# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
# CONSTANTES ET CHEMINS
# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
RAW_DATA_FILENAME: str = "application_train.csv"
PREDICTIONS_FILENAME: str = "predictions_test.parquet"

ARTEFACTS: Dict[str, str] = {
    RAW_DATA_FILENAME: (
        "https://huggingface.co/cantalapiedra/poc_scoring_fair/resolve/"
        "main/application_train.csv"
    ),
    PREDICTIONS_FILENAME: (
        "https://huggingface.co/cantalapiedra/poc_scoring_fair/resolve/"
        "main/predictions_test.parquet"
    ),
}

# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
# T√âL√âCHARGEMENT DES ARTEFACTS
# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
for fname, url in ARTEFACTS.items():
    download_if_missing(fname, url)

# Chargement des donn√©es
df_eda_sample = load_csv_for_eda(RAW_DATA_FILENAME, sample_frac=0.05)
df_preds = load_parquet_file(PREDICTIONS_FILENAME)

# Pour intersectionnalit√©, on fusionne les pr√©dictions avec le CSV complet
df_application: Optional[pd.DataFrame] = None
if df_preds is not None:
    try:
        df_application = pd.read_csv(RAW_DATA_FILENAME, index_col=0)
        df_application = sanitize_feature_names(df_application)
        df_merged = df_application.join(df_preds, how="inner")
    except Exception as e:
        st.error(f"Erreur lors de la fusion application+pr√©dictions : {e}")
        df_merged = None
else:
    df_merged = None

# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
# NAVIGATION
# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
st.sidebar.title("üìä POC Scoring √âquitable")
page_options: List[str] = [
    "Contexte & Objectifs",
    "M√©thodologie",
    "Analyse Exploratoire (EDA)",
    "R√©sultats & Comparaisons",
    "Pr√©diction sur Client S√©lectionn√©",
    "Analyse Intersectionnelle",
    "Courbes ROC & Probabilit√©s - Baseline",
    "Courbes ROC & Probabilit√©s - EO Wrapper",
]
session_key = "current_page_index_poc_scoring_dashboard"
if session_key not in st.session_state:
    st.session_state[session_key] = 0

page: str = st.sidebar.radio(
    "Navigation",
    page_options,
    index=st.session_state[session_key],
    key="nav_radio_poc_scoring_dashboard",
)
if page_options.index(page) != st.session_state[session_key]:
    st.session_state[session_key] = page_options.index(page)


# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
# PAGE : Contexte & Objectifs
# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
if page == "Contexte & Objectifs":
    st.header("Contexte & R√©f√©rences")
    st.markdown(
        """
        **Pourquoi l‚Äô√©quit√© dans le scoring cr√©dit ?**
        - Les r√©gulateurs (comme l‚ÄôIA Act et les lois anti-discrimination) imposent que les mod√®les de scoring cr√©dit n‚Äôavantagent ni ne d√©savantagent un groupe (par exemple le genre).
        - Ce POC compare deux approches :
          1. **LightGBM classique** (mod√®le standard de machine learning)
          2. **LightGBM associ√© √† Fairlearn EG-EO** (ajout d‚Äôune contrainte d‚Äô√©quit√© sur la pr√©diction)

        **Objectif m√©tier :**
        Obtenir un mod√®le performant mais qui reste juste entre les diff√©rents groupes (ex : hommes/femmes).
        """
    )
    st.subheader("Fairlearn")
    st.markdown(
        """
        **Fairlearn** est une librairie open source d√©velopp√©e par Microsoft pour √©valuer et am√©liorer l‚Äô√©quit√© des mod√®les de Machine Learning.  
        Elle fournit :
        - Des m√©triques d‚Äô√©quit√© (DPD, EOD, etc.) pour d√©tecter d‚Äô√©ventuels biais.  
        - Un module de r√©duction (¬´ reductions ¬ª) qui ajuste plusieurs estimateurs afin de satisfaire des contraintes d‚Äô√©quit√©, comme **Equalized Odds** ou **Demographic Parity**.  
        - Des outils de visualisation pour comparer diff√©rentes strat√©gies de mitigation.  

        Pour en savoir plus, consultez la documentation officielle de Fairlearn :  
        [https://fairlearn.org](https://fairlearn.org)  
        (ou le d√©p√¥t GitHub)  
        """
    )

    st.subheader("Papiers de r√©f√©rence")
    with st.expander("Hardt, Price & Srebro (2016) ‚Äì Equalized Odds"):
        st.write(
            """
            **R√©sum√© p√©dagogique :**
            - Equalized Odds impose que le taux de bonne d√©tection (rappel) soit similaire pour chaque groupe (par exemple hommes et femmes), pour les personnes qui remboursent ou non.
            - Un mod√®le respectant bien Equalized Odds limite donc les √©carts d‚Äôerreur selon le groupe sensible.
            """
        )
        st.markdown("[Lire le papier (arXiv)](https://arxiv.org/abs/1610.02413)")

    with st.expander("Agarwal et al. (2019) ‚Äì Exponentiated Gradient"):
        st.write(
            """
            **R√©sum√© p√©dagogique :**
            - L‚Äôalgorithme Exponentiated Gradient combine plusieurs mod√®les en ajustant leurs poids pour trouver un compromis optimal entre performance et √©quit√©.
            - √Ä chaque √©tape, il renforce les mod√®les qui respectent le mieux la contrainte d‚Äô√©quit√©.
            - Cette m√©thode permet d‚Äôobtenir un mod√®le global qui ne discrimine pas, tout en gardant un bon niveau de pr√©diction.
            """
        )
        st.markdown("[Lire le papier (ACM)](https://dl.acm.org/doi/10.1145/3287560.3287572)")

    st.subheader("M√©triques d'√©quit√© utilis√©es")
    st.markdown(
        """
        - **Demographic Parity Difference (DPD) :**
          > Mesure la diff√©rence de taux d‚Äôattribution positive du cr√©dit entre groupes (id√©al : z√©ro diff√©rence).
        - **Equalized Odds Difference (EOD) :**
          > Mesure l‚Äô√©cart de performance du mod√®le (sensibilit√©/sp√©cificit√©) selon le groupe sensible. Un mod√®le √©quitable aura un EOD proche de z√©ro.
        - **Exponentiated Gradient (EG) :**
          > M√©thode pour trouver un compromis entre performance et √©quit√©, en combinant plusieurs mod√®les de fa√ßon intelligente.
        """
    )



# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
# PAGE : M√©thodologie
# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
elif page == "M√©thodologie":
    st.header("M√©thodologie")
    st.subheader("Donn√©es & Pr√©paration")
    st.write(
        """
        - **Jeu de donn√©es** : Home Credit (~300 000 clients, 120 variables socio-√©conomiques).
        - **D√©coupage** : apprentissage (80 %), validation (10 %), test (10 %).
        - **Nettoyage** : gestion des valeurs aberrantes ou manquantes, suppression des doublons, filtrage sur le genre, plafonnement des revenus extr√™mes.
        - **Nouvelles variables** : cr√©ation de ratios simples (ex : mensualit√©/revenu, cr√©dit/revenu), transformation de l‚Äô√¢ge.
        - **Mise en forme** : transformation des variables cat√©gorielles, d√©coupage de l‚Äô√¢ge en tranches, etc.
        - **Encodage & imputation** : gestion automatique des valeurs manquantes et transformation des variables pour les mod√®les.
        - **Nettoyage des noms de features** : standardisation pour √©viter tout probl√®me technique (caract√®res sp√©ciaux, espaces, accents).
        """
    )

    st.subheader("Mod√®le de base (LightGBM)")
    st.write(
        """
        - Mod√®le classique de machine learning pour pr√©dire le d√©faut de remboursement.
        - Prise en compte du d√©s√©quilibre entre bons et mauvais payeurs via `scale_pos_weight`.
        - Le seuil de d√©cision pour cat√©goriser ‚Äúd√©faut‚Äù ou ‚Äúpas d√©faut‚Äù est choisi de fa√ßon optimale sur l‚Äôensemble de validation (indice Youden).
        """
    )

    st.subheader("Mod√®le √©quitable (EG-EO)")
    st.write(
        """
        - LightGBM associ√© √† la contrainte Fairlearn **Equalized Odds** pour garantir l‚Äô√©quit√© entre groupes sensibles (par ex. `CODE_GENDER`).
        - Utilisation de `ExponentiatedGradient` pour combiner plusieurs estimateurs et ajuster leurs poids afin de minimiser l‚Äô√©cart de performance (`EOD`) tout en conservant une bonne AUC.
        - On fixe une tol√©rance maximale (`eps`) sur l‚Äô√©cart d‚Äô√©quit√© autoris√©.
        - Le mod√®le final est un wrapper qui encapsule cette logique et inclut √©galement le seuil de d√©cision optimis√©.
        """
    )

    st.subheader("√âvaluation et comparaison")
    st.write(
        """
        - **Performances mesur√©es** : AUC, pr√©cision, rappel, F1.  
        - **√âquit√©** : v√©rification que le mod√®le ne favorise pas un groupe au d√©triment d‚Äôun autre via **Demographic Parity Difference (DPD)** et **Equalized Odds Difference (EOD)**.  
        - **Analyse d√©taill√©e** : matrices de confusion, taux de s√©lection par groupe sensible, m√©triques d‚Äô√©quit√© globales et par sous-population.
        """
    )

    st.subheader("Accessibilit√© & normes WCAG")
    st.write(
        """
        Pour que le dashboard soit utilisable par les personnes en situation de handicap, nous avons appliqu√© les principes essentiels du **WCAG (Web Content Accessibility Guidelines)** :
        """
    )
    st.markdown(
        """
        1. **Perceivable (Perceptible)**  
           - **Contraste √©lev√©** : palettes de couleurs √† ratio de contraste suffisant (texte et graphiques).  
           - **Texte alternatif & descriptions** : chaque graphique a une description textuelle (‚ÄúDescription : ‚Ä¶‚Äù) pour lecteurs d‚Äô√©cran.  
           - **Taille de police lisible** : textes et annotations respectent une taille minimale.

        2. **Operable (Op√©rable)**  
           - **Navigation clavier** : toutes les interactions (s√©lecteurs, boutons) fonctionnent sans souris.  
           - **Focus visible** : le surlignage des √©l√©ments actifs est clairement visible.  
           - **Temps suffisant** : l‚Äôutilisateur dispose de temps pour comprendre et interagir avant toute expiration de session.

        3. **Understandable (Compr√©hensible)**  
           - **Langage clair** : terminologie simple, explications accessibles, √©vitement du jargon inutile.  
           - **Consistance** : mise en page uniforme et conventions de nommage coh√©rentes (titres, sous-titres, l√©gendes).  
           - **Aide int√©gr√©e** : info-bulle ou l√©gende fournie d√®s qu‚Äôun contr√¥le peut √™tre ambigu.

        4. **Robust (Robuste)**  
           - **Compatibilit√© navigateurs et lecteurs d‚Äô√©cran** : tests effectu√©s sur Chrome, Firefox, NVDA et JAWS.  
           - **Balises HTML s√©mantiques** : via Streamlit, on s‚Äôassure que les √©l√©ments sont correctement reconnus par les aides techniques.

        > En appliquant ces quatre piliers WCAG, nous garantissons que le contenu textuel et graphique reste accessible, y compris aux personnes daltoniennes, malvoyantes ou utilisant un lecteur d‚Äô√©cran.
        """
    )


# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
# PAGE : Analyse Exploratoire (EDA) ‚Äì Distribution selon CODE_GENDER
# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
elif page == "Analyse Exploratoire (EDA)":
    st.header("üîé Analyse Exploratoire des Donn√©es (EDA)")
    st.caption(
        f"Bas√©e sur un √©chantillon de "
        f"{len(df_eda_sample) if df_eda_sample is not None else 0} lignes."
    )

    if df_eda_sample is not None and not df_eda_sample.empty:
        # ‚Ä¶ (vos blocs pr√©c√©dents) ‚Ä¶

        # ‚îÄ‚îÄ R√©partition du genre (CODE_GENDER) ‚îÄ‚îÄ
        if "CODE_GENDER" in df_eda_sample.columns:
            st.subheader("R√©partition par genre ('CODE_GENDER')")
            gender_counts = df_eda_sample["CODE_GENDER"].value_counts()
            gender_percent = df_eda_sample["CODE_GENDER"].value_counts(normalize=True) * 100

            col1, col2 = st.columns(2)
            with col1:
                st.write("Comptage absolu :")
                st.dataframe(gender_counts)
            with col2:
                st.write("Pourcentage :")
                st.dataframe(gender_percent.map("{:.2f}%".format))

            try:
                fig_gender_pie = px.pie(
                    names=gender_counts.index,
                    values=gender_counts.values,
                    title="R√©partition du genre dans l‚Äô√©chantillon",
                    color_discrete_sequence=["#0A0A23", "#FF6600", "#2CA02C"],
                )
                fig_gender_pie.update_traces(textinfo="label+percent", hole=0.4)
                st.plotly_chart(fig_gender_pie, use_container_width=True)
            except Exception as e:
                st.warning(f"Impossible de g√©n√©rer le camembert de genre : {e}")
        else:
            st.info("La colonne 'CODE_GENDER' n‚Äôest pas pr√©sente pour afficher la r√©partition par genre.")

        # ‚îÄ‚îÄ Distribution de 'TARGET' ‚îÄ‚îÄ
        if "TARGET" in df_eda_sample.columns:
            st.subheader("Distribution de la variable cible 'TARGET'")
            target_counts = df_eda_sample["TARGET"].value_counts()
            target_counts_percent = df_eda_sample["TARGET"].value_counts(normalize=True) * 100

            col1, col2 = st.columns(2)
            with col1:
                st.write("Comptage absolu :")
                st.dataframe(target_counts)
            with col2:
                st.write("Pourcentage :")
                st.dataframe(target_counts_percent.map("{:.2f}%".format))

            try:
                fig_target_hist = px.histogram(
                    df_eda_sample,
                    x="TARGET",
                    color="TARGET",
                    title="Histogramme de la variable cible 'TARGET'",
                    labels={"TARGET": "Classe de d√©faut (0 : Non-d√©faut, 1 : D√©faut)"},
                    text_auto=True,
                    color_discrete_sequence=["#1F77B4", "#FF7F0E"],
                )
                fig_target_hist.update_layout(bargap=0.2)
                st.plotly_chart(fig_target_hist, use_container_width=True)
            except Exception as e:
                st.warning(f"Impossible de g√©n√©rer l'histogramme de TARGET : {e}")
        else:
            st.warning("La colonne 'TARGET' n‚Äôest pas pr√©sente dans l‚Äô√©chantillon.")

        # ‚îÄ‚îÄ Distribution de 'AMT_INCOME_TOTAL' ‚îÄ‚îÄ
        numerical_col = "AMT_INCOME_TOTAL"
        if numerical_col in df_eda_sample.columns:
            st.subheader(f"Distribution de '{numerical_col}'")
            df_positive = df_eda_sample[df_eda_sample[numerical_col] > 0]
            if not df_positive.empty:
                cap = df_positive[numerical_col].quantile(0.99)
                df_filtered = df_positive[df_positive[numerical_col] < cap]
            else:
                df_filtered = df_eda_sample
                cap = df_eda_sample[numerical_col].max() if not df_eda_sample.empty else 0

            try:
                fig_income = px.histogram(
                    df_filtered,
                    x=numerical_col,
                    color="TARGET" if "TARGET" in df_filtered.columns else None,
                    marginal="box",
                    title=f"Distribution de '{numerical_col}' (plafonn√© √† {cap:,.0f} si applicable)",
                    labels={numerical_col: "Revenu total", "TARGET": "Classe de d√©faut"},
                    color_discrete_sequence=["#1F77B4", "#FF7F0E"],
                )
                st.plotly_chart(fig_income, use_container_width=True)
            except Exception as e:
                st.warning(f"Impossible de g√©n√©rer l'histogramme de {numerical_col} : {e}")
        else:
            st.info(f"La colonne '{numerical_col}' n‚Äôest pas disponible pour l‚ÄôEDA.")

        # ‚îÄ‚îÄ Menu d√©roulant : distribution d‚Äôune feature selon CODE_GENDER ‚îÄ‚îÄ
        if "CODE_GENDER" in df_eda_sample.columns:
            st.subheader("Distribution d‚Äôune feature selon CODE_GENDER")
            potential_cols = df_eda_sample.select_dtypes(include=[np.number]).columns.tolist()
            # On retire TARGET et AMT_INCOME_TOTAL
            potential_cols = [c for c in potential_cols if c not in ["TARGET", "AMT_INCOME_TOTAL"]]

            chosen_feature = st.selectbox(
                "Choisissez une colonne num√©rique :", [""] + potential_cols
            )
            if chosen_feature:
                st.markdown(f"**Distribution de '{chosen_feature}' par genre**")
                try:
                    fig_feat_gender = px.histogram(
                        df_eda_sample,
                        x=chosen_feature,
                        color="CODE_GENDER",
                        nbins=30,
                        barmode="group",  # barres c√¥te √† c√¥te
                        opacity=0.8,
                        title=f"Distribution de '{chosen_feature}' par CODE_GENDER",
                        labels={chosen_feature: chosen_feature, "CODE_GENDER": "Genre"},
                        color_discrete_map={"M": "#0A0A23", "F": "#FF6600", "XNA": "#2CA02C"},
                    )
                    fig_feat_gender.update_layout(bargap=0.1)
                    # Ajout d'une ligne verticale pour la moyenne globale
                    moyenne_globale = df_eda_sample[chosen_feature].mean()
                    fig_feat_gender.add_vline(
                        x=moyenne_globale,
                        line_color="black",
                        line_dash="dash",
                        annotation_text="Moyenne globale",
                        annotation_position="top right"
                    )
                    st.plotly_chart(fig_feat_gender, use_container_width=True)
                except Exception as e:
                    st.warning(f"Impossible de g√©n√©rer la distribution pour '{chosen_feature}' : {e}")
        # ‚îÄ‚îÄ Fin EDA ‚îÄ‚îÄ

    else:
        st.error("L‚Äô√©chantillon pour l‚ÄôEDA n‚Äôa pas pu √™tre charg√©.")

# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
# PAGE : R√©sultats & Comparaisons
# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
elif page == "R√©sultats & Comparaisons":
    st.header("üìä R√©sultats comparatifs (jeu de validation)")
    if df_preds is not None:
        try:
            # **Extraction des colonnes du DataFrame de pr√©dictions**
            y_true   = df_preds["y_true"]
            y_pred_b = df_preds["y_pred_baseline"]  # 0 = accord, 1 = refus
            y_pred_e = df_preds["y_pred_eo"]        # 0 = accord, 1 = refus
            proba_b  = df_preds["proba_baseline"]
            proba_e  = df_preds["proba_eo"]
            sens     = df_preds["sensitive_feature"]

            # --- Classification Metrics + taux de refus / d‚Äôacceptation global ---
            from sklearn.metrics import (
                roc_auc_score,
                accuracy_score,
                precision_score,
                recall_score,
                f1_score,
            )

            metrics_b = {
                "AUC":                         roc_auc_score(y_true, proba_b),
                "Accuracy":                    accuracy_score(y_true, y_pred_b),
                "Precision (1)":               precision_score(y_true, y_pred_b, pos_label=1, zero_division=0),
                "Recall (1)":                  recall_score(y_true, y_pred_b, pos_label=1, zero_division=0),
                "F1 (1)":                      f1_score(y_true, y_pred_b, pos_label=1, zero_division=0),
                "Taux de refus global":        float(np.mean(y_pred_b)),        # selection_rate
                "Taux d‚Äôacceptation global":   float(1.0 - np.mean(y_pred_b)),
            }
            metrics_e = {
                "AUC":                         roc_auc_score(y_true, proba_e),
                "Accuracy":                    accuracy_score(y_true, y_pred_e),
                "Precision (1)":               precision_score(y_true, y_pred_e, pos_label=1, zero_division=0),
                "Recall (1)":                  recall_score(y_true, y_pred_e, pos_label=1, zero_division=0),
                "F1 (1)":                      f1_score(y_true, y_pred_e, pos_label=1, zero_division=0),
                "Taux de refus global":        float(np.mean(y_pred_e)),
                "Taux d‚Äôacceptation global":   float(1.0 - np.mean(y_pred_e)),
            }

            df_metrics = pd.DataFrame(
                [
                    {"Mod√®le": "Baseline", **metrics_b},
                    {"Mod√®le": "EO Wrapper", **metrics_e},
                ]
            ).set_index("Mod√®le")

            st.subheader("M√©triques de classification")
            st.dataframe(df_metrics.style.format("{:.3f}", na_rep="-"), use_container_width=True)

            # --- Fairness Metrics + taux de refus / d‚Äôacceptation par groupe sensible ---
            mf_b = MetricFrame(
                metrics={"refusal_rate": fairlearn_selection_rate},  # 1 = refus
                y_true=y_true,
                y_pred=y_pred_b,
                sensitive_features=sens,
            )
            mf_e = MetricFrame(
                metrics={"refusal_rate": fairlearn_selection_rate},
                y_true=y_true,
                y_pred=y_pred_e,
                sensitive_features=sens,
            )

            df_sel = pd.DataFrame({
                "Groupe sensible":                  mf_b.by_group.index,
                "Taux de refus Baseline":            mf_b.by_group["refusal_rate"].values,
                "Taux d‚Äôacceptation Baseline":       1.0 - mf_b.by_group["refusal_rate"].values,
                "Taux de refus EO Wrapper":          mf_e.by_group["refusal_rate"].values,
                "Taux d‚Äôacceptation EO Wrapper":     1.0 - mf_e.by_group["refusal_rate"].values,
            }).set_index("Groupe sensible")

            st.subheader("Taux de refus / d‚Äôacceptation par groupe sensible")
            st.dataframe(df_sel.style.format("{:.3f}", na_rep="-"), use_container_width=True)

            # ‚Äî Barplot du taux d‚Äôacceptation ‚Äî
            df_sel_plot = df_sel.reset_index().melt(
                id_vars="Groupe sensible",
                value_vars=["Taux d‚Äôacceptation Baseline", "Taux d‚Äôacceptation EO Wrapper"],
                var_name="Mod√®le",
                value_name="Taux d‚Äôacceptation",
            )
            fig_sel = px.bar(
                df_sel_plot,
                x="Groupe sensible",
                y="Taux d‚Äôacceptation",
                color="Mod√®le",
                barmode="group",
                title="Taux d‚Äôacceptation par groupe sensible et par mod√®le",
                labels={"Groupe sensible": "Groupe sensible", "Taux d‚Äôacceptation": "Taux d‚Äôacceptation"},
            )
            st.plotly_chart(fig_sel, use_container_width=True)

        except Exception as e:
            st.error(f"Erreur lors du calcul/affichage des r√©sultats : {e}")
            st.exception(e)
    else:
        st.warning("Le fichier de pr√©dictions n‚Äôa pas pu √™tre charg√©.")



# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
# PAGE : Pr√©diction sur Client S√©lectionn√©
# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
elif page == "Pr√©diction sur Client S√©lectionn√©":
    st.header("üîç R√©sultats enregistr√©s pour un client (validation)")
    if df_preds is not None:
        client_ids = df_preds.index.tolist()
        if not client_ids:
            st.warning("Aucun ID disponible dans le fichier de pr√©dictions.")
        else:
            max_display = 2000
            ids_to_display = client_ids[:max_display] if len(client_ids) > max_display else client_ids
            if len(client_ids) > max_display:
                st.info(f"Affichage des {max_display} premiers IDs seulement.")
            selected_id = st.selectbox(
                "Choisis un ID client (validation) :", options=[str(i) for i in ids_to_display]
            )
            try:
                sel_id = int(selected_id)
            except ValueError:
                sel_id = selected_id

            if sel_id in df_preds.index:
                row = df_preds.loc[sel_id]
                st.subheader(f"Client ID : {sel_id}")
                st.write(f"Vraie cible (TARGET) : **{row['y_true']}**")
                st.write(f"Probabilit√© Baseline : **{row['proba_baseline']:.4f}**")
                st.write(f"Pr√©diction Baseline : **{row['y_pred_baseline']}**")
                st.write(f"Probabilit√© EO : **{row['proba_eo']:.4f}**")
                st.write(f"Pr√©diction EO : **{row['y_pred_eo']}**")
                st.write(f"Groupe sensible : **{row['sensitive_feature']}**")
            else:
                st.error(f"L‚ÄôID {sel_id} n‚Äôest pas pr√©sent dans le jeu de validation.")
    else:
        st.warning("Le fichier de pr√©dictions n‚Äôa pas pu √™tre charg√©.")


# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
# PAGE : Analyse Intersectionnelle
# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
elif page == "Analyse Intersectionnelle":
    st.header("üîÄ Analyse Intersectionnelle (Optimis√©e Avanc√©e)")
    st.caption(
        "M√©triques de refus/acceptation et d‚Äô√©quit√©, crois√©es avec le genre "
        "et d‚Äôautres variables, avec filtrage, binning par quartile et plot comparatif."
    )

    if df_merged is None:
        st.warning("Fusion des donn√©es application + pr√©dictions impossible.")
        st.stop()

    # === 1. Filtrer selon le genre ===
    genres = df_merged["sensitive_feature"].dropna().unique().tolist()
    selected_genres = st.multiselect(
        "Filtrer par genre (choisis un ou plusieurs) :",
        options=genres,
        default=genres
    )
    df_filtered_gender = df_merged[df_merged["sensitive_feature"].isin(selected_genres)].copy()
    if df_filtered_gender.empty:
        st.warning("Aucun enregistrement pour le(s) genre(s) s√©lectionn√©(s).")
        st.stop()

    # === 2. S√©lection du type de feature √† analyser ===
    feature_type = st.radio(
        "Type de feature √† analyser :",
        ["Cat√©gorielle", "Num√©rique"]
    )

    if feature_type == "Cat√©gorielle":
        candidate_cols = df_filtered_gender.select_dtypes(
            include=["object", "category"]
        ).columns.tolist()
    else:
        candidate_cols = df_filtered_gender.select_dtypes(
            include=[np.number]
        ).columns.tolist()

    excluded_cols = [
        "y_true", "y_pred_baseline", "y_pred_eo",
        "proba_baseline", "proba_eo", "sensitive_feature"
    ]
    candidate_cols = [c for c in candidate_cols if c not in excluded_cols]

    if not candidate_cols:
        st.warning("Aucune colonne disponible pour ce type.")
        st.stop()

    chosen_col = st.selectbox(
        "Choisis une colonne √† analyser :",
        candidate_cols
    )
    df_work = df_filtered_gender.copy()

    # === 3. Binning par quartile pour variables num√©riques, ou conversion en string ===
    if feature_type == "Num√©rique":
        unique_vals = df_work[chosen_col].dropna().unique()
        # Si flag binaire (0/1 ou 1/0), on convertit en "Non"/"Oui"
        if set(unique_vals) <= {0, 1}:
            df_work["MODALITE_ANALYSE"] = df_work[chosen_col].map({0: "Non", 1: "Oui"})
        else:
            # Binning en quartiles avec labels personnalis√©s
            labels_bins = ["Tr√®s faible (Q1)", "Faible (Q2)", "√âlev√© (Q3)", "Tr√®s √©lev√© (Q4)"]
            try:
                df_work["MODALITE_ANALYSE"] = pd.qcut(
                    df_work[chosen_col],
                    q=4,
                    labels=labels_bins,
                    duplicates="drop"
                )
            except Exception:
                # Si qcut √©choue (valeurs identiques ou pas assez de quartiles),
                # on fait un cut en intervalles √©gaux, sans labels
                try:
                    df_work["MODALITE_ANALYSE"] = pd.cut(
                        df_work[chosen_col],
                        bins=4,
                        labels=labels_bins,
                        duplicates="drop"
                    )
                except Exception:
                    st.error(
                        "Impossible d'appliquer un binning par quartile sur cette variable num√©rique."
                    )
                    st.stop()
    else:
        # Cat√©gorie existante (y compris flags encod√©s comme 0/1 pr√©alablement)
        df_work["MODALITE_ANALYSE"] = df_work[chosen_col].astype(str)

    # === 4. Cr√©ation de la modalit√© combin√©e (feature + genre) ===
    df_work["MODALITE_GENRE"] = (
        df_work["MODALITE_ANALYSE"].astype(str) + "_"
        + df_work["sensitive_feature"].astype(str)
    )

    # Import local des m√©triques de classification
    from sklearn.metrics import recall_score, precision_score
    from fairlearn.metrics import (
        equalized_odds_difference,
        demographic_parity_difference,
    )

    # === 5. Calcul des m√©triques pour chaque groupe Modalit√©+Genre ===
    grouped = df_work.groupby("MODALITE_GENRE")

    modalites = []
    support_list = []

    baseline_data = {
        "Taux de refus": [],
        "Taux d‚Äôacceptation": [],
        "Recall": [],
        "Precision": [],
        "EOD": [],
        "DPD": [],
        "Gini": []
    }
    eo_data = {
        "Taux de refus": [],
        "Taux d‚Äôacceptation": [],
        "Recall": [],
        "Precision": [],
        "EOD": [],
        "DPD": [],
        "Gini": []
    }
    delta_data = {
        "Taux de refus": [],
        "Taux d‚Äôacceptation": [],
        "Recall": [],
        "Precision": [],
        "EOD": [],
        "DPD": [],
        "Gini": []
    }

    def gini_coefficient(series: pd.Series) -> float:
        arr = np.array(series, dtype=float)
        if arr.size == 0 or np.all(arr == 0):
            return np.nan
        sorted_arr = np.sort(arr)
        n = len(arr)
        cumvals = np.cumsum(sorted_arr)
        return (1 + (1 / n) - 2 * np.sum(cumvals) / (cumvals[-1] * n))

    for label, group in grouped:
        if group.empty:
            continue
        try:
            y_true = group["y_true"]
            sens = group["sensitive_feature"]

            # --- Baseline ---
            y_pred_b = group["y_pred_baseline"]
            proba_b = group["proba_baseline"]
            refusal_b = float(y_pred_b.mean())
            acceptance_b = 1.0 - refusal_b
            recall_b = recall_score(y_true, y_pred_b, zero_division=0)
            precision_b = precision_score(y_true, y_pred_b, zero_division=0)
            eod_b = equalized_odds_difference(
                y_true, y_pred_b, sensitive_features=sens
            )
            dpd_b = demographic_parity_difference(
                y_true, y_pred_b, sensitive_features=sens
            )
            gini_b = gini_coefficient(proba_b)

            # --- EO Wrapper ---
            y_pred_e = group["y_pred_eo"]
            proba_e = group["proba_eo"]
            refusal_e = float(y_pred_e.mean())
            acceptance_e = 1.0 - refusal_e
            recall_e = recall_score(y_true, y_pred_e, zero_division=0)
            precision_e = precision_score(y_true, y_pred_e, zero_division=0)
            eod_e = equalized_odds_difference(
                y_true, y_pred_e, sensitive_features=sens
            )
            dpd_e = demographic_parity_difference(
                y_true, y_pred_e, sensitive_features=sens
            )
            gini_e = gini_coefficient(proba_e)

            # --- Deltas (EO - Baseline) ---
            delta_refusal = refusal_e - refusal_b
            delta_acceptance = acceptance_e - acceptance_b
            delta_recall = recall_e - recall_b
            delta_precision = precision_e - precision_b
            delta_eod = eod_e - eod_b
            delta_dpd = dpd_e - dpd_b
            delta_gini = gini_e - gini_b

            # Stockage des r√©sultats
            modalites.append(label)
            support_list.append(len(group))

            baseline_data["Taux de refus"].append(refusal_b)
            baseline_data["Taux d‚Äôacceptation"].append(acceptance_b)
            baseline_data["Recall"].append(recall_b)
            baseline_data["Precision"].append(precision_b)
            baseline_data["EOD"].append(eod_b)
            baseline_data["DPD"].append(dpd_b)
            baseline_data["Gini"].append(gini_b)

            eo_data["Taux de refus"].append(refusal_e)
            eo_data["Taux d‚Äôacceptation"].append(acceptance_e)
            eo_data["Recall"].append(recall_e)
            eo_data["Precision"].append(precision_e)
            eo_data["EOD"].append(eod_e)
            eo_data["DPD"].append(dpd_e)
            eo_data["Gini"].append(gini_e)

            delta_data["Taux de refus"].append(delta_refusal)
            delta_data["Taux d‚Äôacceptation"].append(delta_acceptance)
            delta_data["Recall"].append(delta_recall)
            delta_data["Precision"].append(delta_precision)
            delta_data["EOD"].append(delta_eod)
            delta_data["DPD"].append(delta_dpd)
            delta_data["Gini"].append(delta_gini)

        except Exception:
            continue

    # Construction des DataFrames
    df_baseline = pd.DataFrame(baseline_data, index=modalites)
    df_eo = pd.DataFrame(eo_data, index=modalites)
    df_delta = pd.DataFrame(delta_data, index=modalites)
    df_info = pd.DataFrame({"Support": support_list}, index=modalites)

    # Concat√©nation en MultiIndex (Info / Baseline / EO / Delta)
    df_combined = pd.concat(
        {
            "Info": df_info,
            "Baseline": df_baseline,
            "EO": df_eo,
            "Delta": df_delta
        },
        axis=1
    )
    df_combined.index.name = "Modalit√©+Genre"

    # === 6. Filtrer les lignes o√π Œî EOD est diff√©rent de z√©ro (optionnel) ===
    filter_delta_eod = st.checkbox(
        "Afficher uniquement les groupes o√π Œî EOD ‚â† 0",
        value=False
    )
    if filter_delta_eod:
        mask_delta = df_combined[("Delta", "EOD")] != 0
        df_combined = df_combined.loc[mask_delta]
        if df_combined.empty:
            st.warning("Aucun groupe n'a un Œî EOD non nul.")
            st.stop()

    # === 7. Recherche sur les modalit√©s ===
    search_input = st.text_input(
        "Filtrer Modalit√©s (partie du nom) :"
    )
    if search_input:
        mask_search = df_combined.index.str.contains(search_input, case=False, na=False)
        df_filtered = df_combined.loc[mask_search]
    else:
        df_filtered = df_combined.copy()

    if df_filtered.empty:
        st.warning("Aucune modalit√© ne correspond au filtre.")
        st.stop()

    # === 8. S√©lection des m√©triques √† afficher ===
    metrics_dispo = ["Taux de refus", "Taux d‚Äôacceptation", "Recall",
                     "Precision", "EOD", "DPD", "Gini"]
    selected_metrics = st.multiselect(
        "Choisir m√©triques √† afficher (Baseline/EO/Delta) :",
        metrics_dispo,
        default=["Taux de refus", "Recall", "Gini"]
    )

    if not selected_metrics:
        st.warning("S√©lectionne au moins une m√©trique.")
        st.stop()

    # Pr√©parer les sous-DataFrames √† afficher
    cols_baseline = [("Baseline", m) for m in selected_metrics]
    cols_eo = [("EO", m) for m in selected_metrics]
    cols_delta = [("Delta", m) for m in selected_metrics]

    df_be = df_filtered.loc[:, cols_baseline + cols_eo]
    df_deltas = df_filtered.loc[:, cols_delta]

    # Affichage du support (Info)
    if "Info" in df_filtered.columns.get_level_values(0):
        st.subheader("Support (nombre d‚Äôobservations) par groupe")
        st.dataframe(
            df_filtered[("Info", "Support")].to_frame(),
            use_container_width=True
        )

    # Affichage Baseline vs EO
    st.subheader("Comparaison Baseline vs EO")
    st.dataframe(
        df_be.style.format("{:.3f}"),
        use_container_width=True
    )

    # Affichage des Deltas avec mise en forme conditionnelle
    def color_delta(val):
        if pd.isna(val):
            return ""
        return (
            "background-color: lightgreen"
            if val > 0 else
            "background-color: lightcoral"
            if val < 0 else ""
        )

    st.subheader("Delta (EO ‚Äì Baseline)")
    st.dataframe(
        df_deltas.style.format("{:.3f}")
                       .applymap(color_delta),
        use_container_width=True
    )

    # === 9. Plot comparatif pour une m√©trique choisie ===
    st.subheader("Plot comparatif Baseline vs EO")
    # S√©lection d'une m√©trique pour le graphique
    metric_for_plot = st.selectbox(
        "Choisir une m√©trique pour le plot comparatif :",
        selected_metrics
    )
    if metric_for_plot:
        df_plot = pd.DataFrame({
            "Modalit√©+Genre": df_filtered.index.astype(str),
            "Baseline": df_filtered[("Baseline", metric_for_plot)].values,
            "EO": df_filtered[("EO", metric_for_plot)].values,
        })
        fig_comparatif = px.bar(
            df_plot,
            x="Modalit√©+Genre",
            y=["Baseline", "EO"],
            barmode="group",
            title=f"Comparaison Baseline vs EO pour '{metric_for_plot}'",
            labels={"value": metric_for_plot, "variable": "Mod√®le"}
        )
        fig_comparatif.update_layout(xaxis_tickangle=-45)
        st.plotly_chart(fig_comparatif, use_container_width=True)

    # === 10. Export Excel complet ===
    if st.button("üì• Exporter en Excel"):
        import io
        buffer = io.BytesIO()
        with pd.ExcelWriter(buffer, engine="xlsxwriter") as writer:
            df_combined.to_excel(writer, sheet_name="Intersectionnalit√©")
        buffer.seek(0)
        st.download_button(
            label="T√©l√©charger le fichier Excel complet",
            data=buffer,
            file_name="intersectionnalite_genre.xlsx",
            mime="application/vnd.openxmlformats-officedocument."
                 "spreadsheetml.sheet",
        )



# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
# PAGE : Courbes ROC & Probabilit√©s - Baseline
# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
elif page == "Courbes ROC & Probabilit√©s - Baseline":
    st.header("Courbes ROC & Distribution des Probabilit√©s - Baseline")
    st.caption("Bas√© sur le jeu de validation enregistr√© dans 'predictions_validation.parquet'.")

    if df_preds is not None:
        try:
            from sklearn.metrics import roc_auc_score, roc_curve

            y_true = df_preds["y_true"]
            proba_b = df_preds["proba_baseline"]

            fpr, tpr, thresholds = roc_curve(y_true, proba_b)
            auc_val = roc_auc_score(y_true, proba_b)

            fig_roc = px.line(
                x=fpr,
                y=tpr,
                labels={"x": "Taux de faux positifs (FPR)", "y": "Taux de vrais positifs (TPR)"},
                title=f"ROC Baseline (AUC = {auc_val:.3f})",
            )
            fig_roc.add_shape(type="line", x0=0, x1=1, y0=0, y1=1, line=dict(dash="dash", color="gray"))
            st.plotly_chart(fig_roc, use_container_width=True)

            df_dist = pd.DataFrame({"proba_baseline": proba_b, "y_true": y_true.astype(str)})
            fig_dist = px.histogram(
                df_dist,
                x="proba_baseline",
                color="y_true",
                nbins=50,
                barmode="overlay",
                marginal="rug",
                title="Distribution des scores (Baseline)",
                labels={"proba_baseline": "Score Baseline", "y_true": "Vraie cible"},
                color_discrete_map={"0": "green", "1": "red"},
            )
            st.plotly_chart(fig_dist, use_container_width=True)
        except Exception as e:
            st.error(f"Erreur lors de la g√©n√©ration des graphiques : {e}")
            st.exception(e)
    else:
        st.warning("Le fichier de pr√©dictions n‚Äôa pas pu √™tre charg√©.")


# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
# PAGE : Courbes ROC & Probabilit√©s - EO Wrapper
# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
elif page == "Courbes ROC & Probabilit√©s - EO Wrapper":
    st.header("Courbes ROC & Distribution des Probabilit√©s - EO Wrapper")
    st.caption("Bas√© sur le jeu de validation enregistr√© dans 'predictions_validation.parquet'.")

    if df_preds is not None:
        try:
            from sklearn.metrics import roc_auc_score, roc_curve

            y_true = df_preds["y_true"]
            proba_e = df_preds["proba_eo"]

            fpr_e, tpr_e, thresholds_e = roc_curve(y_true, proba_e)
            auc_e_val = roc_auc_score(y_true, proba_e)

            fig_roc_e = px.line(
                x=fpr_e,
                y=tpr_e,
                labels={"x": "Taux de faux positifs (FPR)", "y": "Taux de vrais positifs (TPR)"},
                title=f"ROC EO Wrapper (AUC = {auc_e_val:.3f})",
            )
            fig_roc_e.add_shape(type="line", x0=0, x1=1, y0=0, y1=1, line=dict(dash="dash", color="gray"))
            st.plotly_chart(fig_roc_e, use_container_width=True)

            df_dist_e = pd.DataFrame({"proba_eo": proba_e, "y_true": y_true.astype(str)})
            fig_dist_e = px.histogram(
                df_dist_e,
                x="proba_eo",
                color="y_true",
                nbins=50,
                barmode="overlay",
                marginal="rug",
                title="Distribution des scores (EO Wrapper)",
                labels={"proba_eo": "Score EO", "y_true": "Vraie cible"},
                color_discrete_map={"0": "green", "1": "red"},
            )
            st.plotly_chart(fig_dist_e, use_container_width=True)
        except Exception as e:
            st.error(f"Erreur lors de la g√©n√©ration des graphiques : {e}")
            st.exception(e)
    else:
        st.warning("Le fichier de pr√©dictions n‚Äôa pas pu √™tre charg√©.")


# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
# FIN
# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
